{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nhóm X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import time\n",
    "import threading\n",
    "import nltk\n",
    "from threading import Thread, current_thread\n",
    "from multiprocessing import Process, current_process\n",
    "from nltk import tokenize\n",
    "from fuzzywuzzy import fuzz\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from lxml import etree\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first page ------------------\n",
    "URL = 'https://batdongsan.vn/ban-nha/'\n",
    "\n",
    "# element page -----------------\n",
    "# parse  string list[dict{str: str}]\n",
    "dict_html_parsing = [{'body':''},\\\n",
    "                    {'div': 'landtech-container'},\\\n",
    "                    {'div':  \"uk-container uk-container-center\"},\\\n",
    "                    {'div': \"block-custom realestate-post-detail-custom\"},\\\n",
    "                    {'div': \"uk-grid uk-grid-medium\"},\\\n",
    "                    {'div': \"uk-width-medium-3-5\"},\\\n",
    "                    {'div': \"project-global-object-block-003 information-custom\"},\\\n",
    "                    {'div': \"wrapper\"},\\\n",
    "                    {'div': \"uk-panel\"}]\n",
    "\n",
    "dict_html_house_attribs = list(x for x in dict_html_parsing)\n",
    "dict_html_house_title = list(x for x in dict_html_parsing)\n",
    "dict_html_house_price = list(x for x in dict_html_parsing)\n",
    "\n",
    "dict_html_house_title.extend([{'h1': \"uk-panel-title\"},\\\n",
    "                                                {'span':''}])\n",
    "\n",
    "dict_html_house_price.extend([{'div': \"item\"},\\\n",
    "                                                {'div': \"body\"},\\\n",
    "                                                {'div': \"meta\"},\\\n",
    "                                                {'strong': \"price\"}])\n",
    "\n",
    "dict_html_house_attribs.extend([{'div': \"item\"},\\\n",
    "                                                {'div': \"body\"},\\\n",
    "                                                {'div': \"param\"},\\\n",
    "                                                {'ul': \"uk-list\"}])\n",
    "\n",
    "dict_html__main_page =[{'body': ''},\\\n",
    "                        {'div': 'landtech-container'},\\\n",
    "                        {'div': 'uk-container uk-container-center'},\\\n",
    "                        {'div': 'uk-grid uk-grid-small'},\\\n",
    "                        {'div': 'uk-width-medium-7-10'},\\\n",
    "                        {'div': 'project-global-object-block-002 realestate-post-list-custom block-custom'},\\\n",
    "                        {'div': 'wrapper'},\\\n",
    "                        {'div': 'uk-panel'},\\\n",
    "                        {'div': 'datalist'},\\\n",
    "                        {'div': 'uk-grid uk-grid-small uk-grid-width-1-1'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Title, Price, Address, Area, Room, WC, Direction, Description]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "header_features = ['Title', 'Price', 'Address', 'Area', 'Room', 'WC' , 'Direction', 'Description']\n",
    "house_dataframe = pd.DataFrame(columns = header_features)\n",
    "print(house_dataframe)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_request(url):\n",
    "    try:\n",
    "        response_ = requests.get(url, timeout=10)\n",
    "        if response_.status_code == 200:\n",
    "            soup = BeautifulSoup(response_.content, \"html.parser\")\n",
    "            dom = etree.HTML(str(soup))\n",
    "            xpath_str_next = '//*[@id=\"realestate-search\"]/body/div[6]/div/div/div[1]/div[1]/div/div/div[2]/div'\n",
    "            if len(dom.xpath(xpath_str_next)) > 0:\n",
    "                response_.close()\n",
    "                return True\n",
    "            else: \n",
    "                response_.close()\n",
    "                return False\n",
    "        else:\n",
    "            response_.close()\n",
    "            return False\n",
    "    except (requests.exceptions.ConnectionError, requests.exceptions.Timeout):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Address:\n",
    "    def __init__(self, city, district, ward, street):\n",
    "        self._city = city\n",
    "        self._district = district\n",
    "        self._ward = ward\n",
    "        self._street = street\n",
    "        \n",
    "    def display(self):\n",
    "        print(self._street, self._ward, self._district, self._city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class House:\n",
    "    def __init__(self, title,  price ,address, area, room, wc, direction, description):\n",
    "        self._title = title\n",
    "        self._price = price\n",
    "        self._address = address\n",
    "        self._area= area \n",
    "        self._room = room \n",
    "        self._wc = wc\n",
    "        self._direction = direction\n",
    "        self._description = description\n",
    "    \n",
    "    def scrappingDataWeb(self, url):\n",
    "        page = requests.get(url, timeout = 3)\n",
    "        # title parsing\n",
    "        soup_title = BeautifulSoup(page.content, \"html.parser\")\n",
    "        for item in dict_html_house_title:\n",
    "            if list(item.values())[0] != '':\n",
    "                temp = soup_title.find(list(item.keys())[0], class_ = item.get(list(item.keys())[0]))\n",
    "                soup_title = temp\n",
    "            else:\n",
    "                temp = soup_title.find(list(item.keys())[0])\n",
    "                soup_title = temp\n",
    "        self._title = soup_title.text\n",
    "        \n",
    "        # price parsing\n",
    "        soup_price = BeautifulSoup(page.content, \"html.parser\")\n",
    "        for item in dict_html_house_price:\n",
    "            if item.get(list(item.keys())[0]) != '':\n",
    "                soup_price = soup_price.find(list(item.keys())[0], class_ = item.get(list(item.keys())[0]))\n",
    "            else:\n",
    "                soup_price = soup_price.find(list(item.keys())[0])\n",
    "        self._price = soup_price.text\n",
    "        \n",
    "        ## parsing another attributes\n",
    "        soup_attrib = BeautifulSoup(page.content, \"html.parser\")\n",
    "        for item in dict_html_house_attribs:\n",
    "            if list(item.values())[0] != '':\n",
    "                soup_attrib = soup_attrib.find(list(item.keys())[0], class_ = item.get(list(item.keys())[0]))\n",
    "            else: \n",
    "                soup_attrib = soup_attrib.find(list(item.keys())[0])\n",
    "        attrib_root = soup_attrib.find_all(\"li\")\n",
    "        for root in attrib_root:\n",
    "            if root.find('strong').text == \"Diện tích:\":\n",
    "                self._area = root.text\n",
    "            if root.find('strong').text == \"Địa chỉ:\":\n",
    "                self._address == root.text\n",
    "            if root.find('strong').text == \"Phòng ngủ:\":\n",
    "                self._room = root.text\n",
    "            if root.find('strong').text == \"Phòng WC:\":\n",
    "                self._wc = root.text\n",
    "            if root.find('strong').text == \"Hướng nhà:\":\n",
    "                self._direction = root.text\n",
    "    \n",
    "        soup_des = BeautifulSoup(page.content, \"html.parser\")\n",
    "        dom = etree.HTML(str(soup_des))\n",
    "        xpath_str = '//*[@id=\"post-detail\"]/body/div[7]/div/div/div[1]/div[1]/div/div/div/div/div/p' # The XPath expression for the blog's title\n",
    "        soup_des = (dom.xpath(xpath_str)[0])\n",
    "        temp_text = soup_des.text\n",
    "        for item in soup_des.iter():\n",
    "            temp_text = ''.join([temp_text, item.tail])\n",
    "        self._description = temp_text\n",
    "        ## chỉnh sửa phần này thành nhiều thành phần attib\n",
    "        \n",
    "    \n",
    "    ## attributes matching for finding address base on The compare with voacabulary embedded database with Levhein distance\n",
    "    def tranferDescription(self, embedded_database): \n",
    "        temp_address = Address('','','','')\n",
    "        for city in embedded_database:\n",
    "            for district in city._container:\n",
    "                ## tokenize description scrapping from web to list vocab\n",
    "                for token in tokenize(self._description):\n",
    "                    # compare each vocab with each item address from db\n",
    "                    score = fuzz(token, district)\n",
    "                    if score >= 0.7:\n",
    "                        Address._district = district\n",
    "        return\n",
    "    \n",
    "    ##\n",
    "    def tranferAddress(self):\n",
    "        return\n",
    "    \n",
    "    def houseToDataframe(self, data_frame):\n",
    "        new_df = pd.DataFrame(data = [[self._title,\\\n",
    "                                self._price,\\\n",
    "                                self._address,\\\n",
    "                                self._area,\\\n",
    "                                self._room,\\\n",
    "                                self._wc,\\\n",
    "                                self._direction,\\\n",
    "                                self._description]],\\\n",
    "                                columns = header_features)\n",
    "        data_frame = pd.concat([data_frame,new_df], axis =0)\n",
    "        return data_frame\n",
    "    \n",
    "    def display(self):\n",
    "        print(self._title, \"\\n\",\\\n",
    "              self._price, \"\\n\",\\\n",
    "              self._address, \"\\n\",\\\n",
    "              self._area, \"\\n\",\\\n",
    "              self._room, \"\\n\",\\\n",
    "              self._wc, \"\\n\",\\\n",
    "              self._direction, \"\\n\",\\\n",
    "              self._description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HouseContainer:\n",
    "    def __init__(self, list_in = []):\n",
    "        self._house_container = list_in\n",
    "        self._url_container = []\n",
    "        self._url_house_container = []\n",
    "        self._size = len(self._house_container)\n",
    "    \n",
    "    def parsingUrlContainer(self):\n",
    "        index = 1\n",
    "        temp = URL\n",
    "        while process_request(temp) == True:\n",
    "            self._url_container.append(temp)\n",
    "            index +=1;\n",
    "            elem = ''.join(['p',str(index)])\n",
    "            temp = ''.join([URL, elem])\n",
    "        \n",
    "    def pasingHouseContainer(self):\n",
    "        for item in self._url_container:\n",
    "            page = requests.get(item)\n",
    "            soup_main_page =  BeautifulSoup(page.content, \"html.parser\")\n",
    "            for item in dict_html__main_page:\n",
    "                if list(item.values())[0] != '':\n",
    "                    soup_main_page = soup_main_page.find(list(item.keys())[0], class_ = item.get(list(item.keys())[0]))\n",
    "                else: \n",
    "                    soup_main_page = soup_main_page.find(list(item.keys())[0])\n",
    "            soup_main_page = soup_main_page.find_all('div')\n",
    "            for item in soup_main_page:\n",
    "                try: \n",
    "                    item = item.find('div', class_ = 'item')\n",
    "                    item = item.find('div', class_ = 'body')\n",
    "                    item = item.find('div', class_ = 'name')\n",
    "                    item = item.find('a',  href=True)\n",
    "                    self._url_house_container.append(item['href'])  \n",
    "                except:\n",
    "                    try:\n",
    "                        item = item.find('div', class_ = 'item vip')\n",
    "                        item = item.find('div', class_ = 'body')\n",
    "                        item = item.find('div', class_ = 'name')\n",
    "                        item = item.find('a',  href=True)\n",
    "                        self._url_house_container.append(item['href'])\n",
    "                    except:\n",
    "                        try:\n",
    "                            item = item.find('div', class_ = 'item highlight ')\n",
    "                            item = item.find('div', class_ = 'body')\n",
    "                            item = item.find('div', class_ = 'name')\n",
    "                            item = item.find('a',  href=True)\n",
    "                            self._url_house_container.append(item['href'])\n",
    "                        except:\n",
    "                            try:\n",
    "                                item = item.find_all('div')[0]\n",
    "                                item = item.find('div', class_ = 'body')\n",
    "                                item = item.find('div', class_ = 'name')\n",
    "                                item = item.find('a',  href=True)\n",
    "                                self._url_house_container.append(item['href'])\n",
    "                            except:\n",
    "                                pass\n",
    "    \n",
    "    def parsingHouseUrl(self):\n",
    "        for url in self._url_house_container:\n",
    "            try:\n",
    "                temp = House(\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\")\n",
    "                temp.scrappingDataWeb(url)\n",
    "                self._house_container.append(temp)\n",
    "                self._size = len(self._house_container) \n",
    "                print('epoch: ', self._size +1)\n",
    "            except : pass\n",
    "        \n",
    "    def displayUrl(self):\n",
    "        for item in self._url_container:\n",
    "            print(item)\n",
    "    \n",
    "    def displayUrlHouse(self):\n",
    "        for item in self._url_house_container:\n",
    "            print(item)\n",
    "    \n",
    "    def displayHouse(self):\n",
    "        for house in self._house_container:\n",
    "            house.display()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_container = HouseContainer([])\n",
    "house_container.parsingUrlContainer()\n",
    "house_container.displayUrl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_container.pasingHouseContainer()\n",
    "house_container.displayUrlHouse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_container.parsingHouseUrl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for house in house_container._house_container:\n",
    "    house_dataframe = house.houseToDataframe(house_dataframe)\n",
    "print(house_dataframe)\n",
    "house_dataframe.to_excel('data.xlsx')\n",
    "                                                                                                                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
