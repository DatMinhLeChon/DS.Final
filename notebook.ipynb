{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from fuzzywuzzy import fuzz\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = r'https://batdongsan.vn/ban-nha/'\n",
    "\n",
    "dict_html_parsing = [\n",
    "                    {'body':''},\\\n",
    "                    {'div': 'landtech-container'},\\\n",
    "                    {'div':  \"uk-container uk-container-center\"},\\\n",
    "                    {'div': \"block-custom realestate-post-detail-custom\"},\\\n",
    "                    {'div': \"uk-grid uk-grid-medium\"},\\\n",
    "                    {'div': \"uk-width-medium-3-5\"},\\\n",
    "                    {'div': \"project-global-object-block-003 information-custom\"},\\\n",
    "                    {'div': \"wrapper\"},\\\n",
    "                    {'div': \"uk-panel\"}]\n",
    "\n",
    "dict_html_house_title = dict_html_parsing.extend([{'h1': \"uk-panel-title\"},\\\n",
    "                                                {'span':''}])\n",
    "\n",
    "dict_html_house_price = dict_html_parsing.extend([{'div': \"item\"},\\\n",
    "                                                {'div': \"body\"},\\\n",
    "                                                {'div': \"meta\"},\\\n",
    "                                                {'strong': \"price\"}])\n",
    "\n",
    "dict_html_house_attribs = dict_html_parsing.extend([{'div': \"item\"},\\\n",
    "                                                {'div': \"body\"},\\\n",
    "                                                {'div': \"param\"},\\\n",
    "                                                {'ul', \"uk-list\"},\\\n",
    "                                                {'li': ''}])\n",
    "\n",
    "header_features = ['Price', 'Title', 'Address', 'Area', 'Room', 'WC' , 'Des']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Address:\n",
    "    def __init__(self, city, district, ward, street):\n",
    "        self._city = city\n",
    "        self._district = district\n",
    "        self._ward = ward\n",
    "        self._street = street\n",
    "    \n",
    "    def display(self):\n",
    "        print(self._street, self._ward, self._district, self._city)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class House:\n",
    "    def __init__(self, title,  price ,address, area, room, wc, description):\n",
    "        self._title = title\n",
    "        self._price = price\n",
    "        self._address = address\n",
    "        self._area= area \n",
    "        self._room = room \n",
    "        self._wc = wc\n",
    "        self._description = description\n",
    "    \n",
    "    def scrappingDataWeb(self, url):\n",
    "        page = requests.get(url)\n",
    "        soup_attrib = BeautifulSoup(page.content, \"html.parser\")\n",
    "        soup_price = BeautifulSoup(page.content, \"html.parser\")\n",
    "        soup_title = BeautifulSoup(page.content, \"html.parser\")\n",
    "        \n",
    "        # title parsing\n",
    "        \n",
    "        for item in dict_html_house_title:\n",
    "            print(item.key())\n",
    "            if item.value != '':\n",
    "                soup_title = soup_title.find(item, class_ = item.value)\n",
    "            else:\n",
    "                soup_title = soup_title.find(item)\n",
    "        self._title = soup_title.text\n",
    "        \n",
    "        # price parsing\n",
    "        try:\n",
    "            for item in dict_html_house_price:\n",
    "                if item.value != '':\n",
    "                    soup_price = soup_price.find(item, class_ = item.value)\n",
    "                else:\n",
    "                    soup_price = soup_price.find(item)\n",
    "            self._price = soup_price.text\n",
    "        except:\n",
    "            print(\"error parsing price: \", url)\n",
    "        \n",
    "        ## parsing another attributes\n",
    "        try:\n",
    "            for item in dict_html_house_attribs:\n",
    "                if item.value != '':\n",
    "                    soup_attrib = soup_attrib.find(item, class_ = item.value)\n",
    "                else:\n",
    "                    soup_attrib = soup_attrib.find(item)\n",
    "            attrib_root = soup_attrib.findall(\"i\")\n",
    "            for root in attrib_root:\n",
    "                item = root.find(\"strong\")\n",
    "                if item.innerHTML ==\"Diện tích:\":\n",
    "                    self._area = item.text\n",
    "                elif item.innerHTML ==\"Phòng ngủ:\":\n",
    "                    self._room == item.text\n",
    "                elif item.innerHTML ==\"Địa chỉ:\":\n",
    "                    self._address = item.text\n",
    "        except:\n",
    "            print(\"error parsing attribs: \", url)\n",
    "            \n",
    "        ## chỉnh sửa phần này thành nhiều thành phần attib\n",
    "        \n",
    "    \n",
    "    ## attributes matching for finding address base on The compare with voacabulary embedded database with Levhein distance\n",
    "    def tranferDescription(self, embedded_database): \n",
    "        temp_address = Address('','','','')\n",
    "        for city in embedded_database:\n",
    "            for district in city._container:\n",
    "                ## tokenize description scrapping from web to list vocab\n",
    "                for token in tokenize(self._description):\n",
    "                    # compare each vocab with each item address from db\n",
    "                    score = fuzz(token, district)\n",
    "                    if score >= 0.7:\n",
    "                        Address._district = district\n",
    "        return\n",
    "    \n",
    "    ##\n",
    "    def tranferAddress(self):\n",
    "        return\n",
    "    def display(self):\n",
    "        print(self._title,\\\n",
    "              self._price,\\\n",
    "              self._address,\\\n",
    "              self._area,\\\n",
    "              self._room,\\\n",
    "              self._wc,\\\n",
    "              self._description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m temp \u001b[39m=\u001b[39m House(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m temp\u001b[39m.\u001b[39;49mscrappingDataWeb(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://batdongsan.vn/ban-nha-pho-cu-loc-thanh-xuan-56m-4-tang-gia-545-ty-r268420\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m, in \u001b[0;36mHouse.scrappingDataWeb\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     15\u001b[0m soup_title \u001b[39m=\u001b[39m BeautifulSoup(page\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39m# title parsing\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m dict_html_house_title:\n\u001b[1;32m     20\u001b[0m         \u001b[39mif\u001b[39;00m item\u001b[39m.\u001b[39mvalue \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     21\u001b[0m             soup_title \u001b[39m=\u001b[39m soup_title\u001b[39m.\u001b[39mfind(item, class_ \u001b[39m=\u001b[39m item\u001b[39m.\u001b[39mvalue)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "temp = House(\"\",\"\",\"\",\"\",\"\",\"\",\"\")\n",
    "temp.scrappingDataWeb(\"https://batdongsan.vn/ban-nha-pho-cu-loc-thanh-xuan-56m-4-tang-gia-545-ty-r268420\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContainerHouse:\n",
    "    def __init__(self, _list = []):\n",
    "        self._size = len(self._list)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
