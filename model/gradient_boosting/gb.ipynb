{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m evs \u001b[39m=\u001b[39m explained_variance_score(data\u001b[39m.\u001b[39my_test, y_pred)\n\u001b[1;32m     41\u001b[0m r2 \u001b[39m=\u001b[39m r2_score(data\u001b[39m.\u001b[39my_test, y_pred)\n\u001b[0;32m---> 42\u001b[0m recall \u001b[39m=\u001b[39m recall_score(data\u001b[39m.\u001b[39;49my_test, y_pred)\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMSE: \u001b[39m\u001b[39m\"\u001b[39m, mse)\n\u001b[1;32m     45\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMAE: \u001b[39m\u001b[39m\"\u001b[39m, mae)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2098\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecall_score\u001b[39m(\n\u001b[1;32m   1968\u001b[0m     y_true,\n\u001b[1;32m   1969\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1975\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1976\u001b[0m ):\n\u001b[1;32m   1977\u001b[0m     \u001b[39m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   1978\u001b[0m \n\u001b[1;32m   1979\u001b[0m \u001b[39m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[39m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   2097\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2098\u001b[0m     _, r, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   2099\u001b[0m         y_true,\n\u001b[1;32m   2100\u001b[0m         y_pred,\n\u001b[1;32m   2101\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   2102\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   2103\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   2104\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   2105\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   2106\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   2107\u001b[0m     )\n\u001b[1;32m   2108\u001b[0m     \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1372\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1375\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/metrics/_classification.py:106\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmultilabel-indicator\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m    108\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    109\u001b[0m     y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score, recall_score, precision_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class splitData():\n",
    "    def __init__(self):\n",
    "        self.X_train = []\n",
    "        self.X_test = []\n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "    \n",
    "    def split(self, x, y):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(x, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "features = ['district_encoder',\\\n",
    "        'area',\\\n",
    "        'new_num_floors',\\\n",
    "        'new_bedrooms',\\\n",
    "        'houseTypes_Bán Luxury home',\\\n",
    "        'houseTypes_Bán Nhà',\\\n",
    "        'houseTypes_Bán Nhà cổ',\\\n",
    "        'houseTypes_Bán Nhà mặt phố',\\\n",
    "        'houseTypes_Bán Nhà riêng']\n",
    "\n",
    "df = pd.read_excel('HCM_data.xlsx')\n",
    "df_tranform = pd.DataFrame(data = StandardScaler().fit_transform(df.loc[:, features].values), columns = features)\n",
    "y = df['price'].values\n",
    "x = df_tranform[features].values\n",
    "data = splitData()\n",
    "data.split(x, y)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(data.X_train, data.y_train)\n",
    "y_pred = model.predict(data.X_test)\n",
    "mse = mean_squared_error(data.y_test, y_pred)\n",
    "mae = mean_absolute_error(data.y_test, y_pred)\n",
    "evs = explained_variance_score(data.y_test, y_pred)\n",
    "r2 = r2_score(data.y_test, y_pred)\n",
    "recall = recall_score(data.y_test, y_pred)\n",
    "\n",
    "print(\"MSE: \", mse)\n",
    "print(\"MAE: \", mae)\n",
    "print(\"variance: \", evs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
